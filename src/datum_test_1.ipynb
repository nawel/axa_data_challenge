{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import graphlab as gl\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pickle.load(open(\"/Users/ozad/Desktop/axa_data_challenge-master/callsData_DataFrame.obj\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor x in data.head() :\\n        print type(data[x])\\nprint  data.head()\\nprint len(data)\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for x in data.head() :\n",
    "        print type(data[x])\n",
    "print  data.head()\n",
    "print len(data)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class FeatureExtractorClf(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y_df):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X_df):\n",
    "\n",
    "        XX = np.array([np.array(dd) for dd in X_df['ASS_ASSIGNMENT']])\n",
    "        return XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.n_components = 8\n",
    "        self.n_estimators = 400\n",
    "        self.clf = Pipeline([\n",
    "            ('pca', PCA(n_components=self.n_components)), \n",
    "            #('pca',  KernelPCA(n_components=21,kernel=\"rbf\",remove_zero_eig=True,gamma=0.0004)),\n",
    "            \n",
    "            ####### Basic algo :  Random Forest Classifier\n",
    "            #('clf', RandomForestClassifier(n_estimators=self.n_estimators, random_state=42))\n",
    "            \n",
    "            ####### GradientBoost\n",
    "            #('clf', GradientBoostingClassifier(n_estimators=self.n_estimators,max_depth=1000,subsample=0.85,\n",
    "            #       max_features='log2',random_state=42))\n",
    "                    \n",
    "                 \n",
    "           ####### AdaBoost avec DecisionTreeClassifier\n",
    "            ('clf', AdaBoostClassifier(\n",
    "                   base_estimator=DecisionTreeClassifier(max_depth=8),\n",
    "                   n_estimators=100,\n",
    "                   learning_rate=1.6,\n",
    "                   random_state=42,\n",
    "                   algorithm='SAMME',\n",
    "               ))\n",
    "                \n",
    "            #('clf', QuadraticDiscriminantAnalysis()),\n",
    "            #('clf', LinearDiscriminantAnalysis(solver='svd', shrinkage=None, priors=None, n_components=10, store_covariance=True, tol=0.01))\n",
    "            \n",
    "                \n",
    "                \n",
    "            ####### AdaBoost avec GradientBoostingClassifier\n",
    "            #('clf', AdaBoostClassifier(\n",
    "            #    base_estimator=GradientBoostingClassifier(n_estimators=10000,max_depth=10,\n",
    "            #       subsample=0.5,\n",
    "            #       max_features='log2'),\n",
    "            #    n_estimators=500,\n",
    "            #    learning_rate=1,\n",
    "            #    random_state=42,\n",
    "            #    algorithm='SAMME',\n",
    "            #))    \n",
    "            \n",
    "                \n",
    "            ####### AdaBoost avec SVC\n",
    "            #('clf', AdaBoostClassifier(\n",
    "            #    svc(probability=True, kernel='linear'),\n",
    "            #    n_estimators=10,\n",
    "            #    learning_rate=1,\n",
    "            #    random_state=42,\n",
    "            #    algorithm='SAMME',\n",
    "            #))\n",
    "                \n",
    "                \n",
    "            ####### AdaBoost avec GaussianNB\n",
    "            #('clf', AdaBoostClassifier(\n",
    "            #    GaussianNB(),\n",
    "            #  n_estimators=10,\n",
    "            #  learning_rate=1,\n",
    "            #  random_state=42,\n",
    "            #  algorithm='SAMME',\n",
    "            #))\n",
    "\n",
    "        \n",
    "            ####### AdaBoost avec SGDClassifier ou SVC\n",
    "            #('clf', AdaBoostClassifier(\n",
    "            #SGDClassifier(loss='log'),\n",
    "            #n_estimators=10000,\n",
    "            #learning_rate=1.6,\n",
    "            #random_state=42,\n",
    "            #algorithm='SAMME',\n",
    "             #))\n",
    "                \n",
    "\n",
    "            ####### Bayesien \n",
    "            #('clf',  GaussianNB())\n",
    "            \n",
    "            ####### Multinomial NB\n",
    "            #('clf', MultinomialNB(alpha=0.1, fit_prior=True, class_prior=None))\n",
    "                \n",
    "            ####### SGD \n",
    "            # ('clf',  SGDClassifier(loss='log')\n",
    "\n",
    "\n",
    "                ])        \n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = data['CSPL_RECEIVED_CALLS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print len( data['ASS_PARTNER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_df=data['CSPL_RECEIVED_CALLS'][:300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n"
     ]
    }
   ],
   "source": [
    "y_try=data['CSPL_RECEIVED_CALLS'][:3000000]\n",
    "print len(y_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n"
     ]
    }
   ],
   "source": [
    "print len(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df=data[  ['WEEK_END',  'DAY_WE_DS',  'TPER_TEAM',  'ASS_ASSIGNMENT',  'ASS_DIRECTORSHIP','ASS_PARTNER']][:300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n"
     ]
    }
   ],
   "source": [
    "print len(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nfrom sklearn.model_selection import ShuffleSplit\\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\\n\\ndef train_test_model_clf(X_df, y_df, skf_is, FeatureExtractor, Classifier):\\n    \\n    train_is, test_is = skf_is\\n    \\n   \\n    \\n    # Feature extraction\\n    fe_clf = FeatureExtractor()\\n    fe_clf.fit(X_train_df, y_train_df)\\n    \\n    X_train_array_clf = fe_clf.transform(X_train_df)\\n    X_test_array_clf = fe_clf.transform(X_test_df)\\n    \\n\\n    # Train\\n    clf = Classifier()\\n    clf.fit(X_train_array_clf, y_train_clf)\\n    # Test \\n    y_proba_clf = clf.predict_proba(X_test_array_clf)                        \\n    y_pred_clf = labels[np.argmax(y_proba_clf, axis=1)]#on somme les 4 valeurs pour obtenir le label  \\n    #print y_proba_clf\\n    #print y_pred_clf\\n    #print np.argmax(y_proba_clf, axis=1)\\n    error = 1 - accuracy_score(y_test_clf, y_pred_clf)                       \\n    print('error = %s' % error)                                                                            \\n    print('classification report:\\n %s' % classification_report(y_test_clf, y_pred_clf))\\n    print('confusion matrix:\\n %s' % confusion_matrix(y_test_clf, y_pred_clf))\\n\\n\\nskf = ShuffleSplit(n_splits=2, test_size=0.2, random_state=57)  \\nskf_is = list(skf.split(X_df))[0]\\n\\ntrain_test_model_clf(X_df, y_df, skf_is, FeatureExtractorClf, Classifier)\\n\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def train_test_model_clf(X_df, y_df, skf_is, FeatureExtractor, Classifier):\n",
    "    \n",
    "    train_is, test_is = skf_is\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Feature extraction\n",
    "    fe_clf = FeatureExtractor()\n",
    "    fe_clf.fit(X_train_df, y_train_df)\n",
    "    \n",
    "    X_train_array_clf = fe_clf.transform(X_train_df)\n",
    "    X_test_array_clf = fe_clf.transform(X_test_df)\n",
    "    \n",
    "\n",
    "    # Train\n",
    "    clf = Classifier()\n",
    "    clf.fit(X_train_array_clf, y_train_clf)\n",
    "    # Test \n",
    "    y_proba_clf = clf.predict_proba(X_test_array_clf)                        \n",
    "    y_pred_clf = labels[np.argmax(y_proba_clf, axis=1)]#on somme les 4 valeurs pour obtenir le label  \n",
    "    #print y_proba_clf\n",
    "    #print y_pred_clf\n",
    "    #print np.argmax(y_proba_clf, axis=1)\n",
    "    error = 1 - accuracy_score(y_test_clf, y_pred_clf)                       \n",
    "    print('error = %s' % error)                                                                            \n",
    "    print('classification report:\\n %s' % classification_report(y_test_clf, y_pred_clf))\n",
    "    print('confusion matrix:\\n %s' % confusion_matrix(y_test_clf, y_pred_clf))\n",
    "\n",
    "\n",
    "skf = ShuffleSplit(n_splits=2, test_size=0.2, random_state=57)  \n",
    "skf_is = list(skf.split(X_df))[0]\n",
    "\n",
    "train_test_model_clf(X_df, y_df, skf_is, FeatureExtractorClf, Classifier)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "End.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "clf3 = SGDClassifier()\n",
    "clf = AdaBoostClassifier(\n",
    "                   base_estimator=DecisionTreeClassifier(max_depth=8),\n",
    "                   n_estimators=100,\n",
    "                   learning_rate=1.6,\n",
    "                   random_state=42,\n",
    "                   algorithm='SAMME',\n",
    "               )\n",
    "clf2=Classifier()\n",
    "if len(X_df) > 0:\n",
    "    print \"Training...\"\n",
    "    X = np.array(X_df)\n",
    "    y = np.array(y_df).ravel()\n",
    "    clf.fit(X,y)\n",
    "print \"End.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data submission...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-520b4ee4338a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdate1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdate2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mass_assignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mass_assignment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"Loading the data submission...\")\n",
    "file = open('/Users/ozad/Desktop/AXA/submission.txt','r')\n",
    "lines = [line.rstrip('\\n') for line in file]\n",
    "lines = lines[1:]\n",
    "submission = []\n",
    "for line in lines:\n",
    "    tokens = line.split()\n",
    "    date1 = tokens[0].split(\"-\")\n",
    "    date2 = tokens[1].split(\":\")\n",
    "    date = datetime(int(date1[0]),int(date1[1]),int(date1[2]),int(date2[0]),int(date2[1]))\n",
    "    ass_assignment = ' '.join(tokens[2:-1])\n",
    "    submission.append((date, ass_assignment))\n",
    "print \"End.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print \"Loading data for validation...\"\n",
    "posTest=6820\n",
    "d_test = submission[posTest][0]\n",
    "X_test = []\n",
    "pos3=0\n",
    "while pos3 < m and submission[pos3][0] < d_test:\n",
    "    ass_assignment = submission[pos3][1]\n",
    "    X_test.append([ ass_num[ass_assignment] ])\n",
    "    pos3 += 1\n",
    "print \"End.\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Prediction...\"\n",
    "if len(X_test) > 0:\n",
    "    X_test = array(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "print pos3\n",
    "print \"End.\"\n",
    "\n",
    "####### affichage \n",
    "for i in range(pos3):\n",
    "    print \"%d-%d-%d %d:%d:00.000\\t%s\\t%d\" % (submission[i][0].year,\n",
    "        submission[i][0].month, submission[i][0].day,\n",
    "        submission[i][0].hour, submission[i][0].minute, submission[i][1],\n",
    "        y_pred[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
