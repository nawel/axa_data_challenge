{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import graphlab as gl\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pickle.load(open(\"/Users/ozad/Desktop/axa_data_challenge-master/callsData_DataFrame.obj\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DAY_OFF  WEEK_END  DAY_WE_DS  TPER_TEAM  ASS_ASSIGNMENT  ASS_DIRECTORSHIP  \\\n",
      "0        0         1          6          1              27                 4   \n",
      "1        0         1          6          1              27                 4   \n",
      "2        0         1          6          1              27                 4   \n",
      "3        0         1          6          1              27                 4   \n",
      "4        0         1          6          1              27                 4   \n",
      "\n",
      "   ASS_PARTNER  ASS_POLE  CSPL_CALLSOFFERED  CSPL_NOANSREDIR   ...    \\\n",
      "0           15         9                0.0              0.0   ...     \n",
      "1           15         9                0.0              0.0   ...     \n",
      "2           15         9                0.0              0.0   ...     \n",
      "3           15         9                0.0              0.0   ...     \n",
      "4           15         9                1.0              0.0   ...     \n",
      "\n",
      "   CSPL_ACCEPTABLE  CSPL_MAXSTAFFED  CSPL_ABANDONNED_CALLS  CSPL_CALLS  \\\n",
      "0              0.0              3.0                    0.0         0.0   \n",
      "1              0.0              7.0                    0.0         0.0   \n",
      "2              0.0              4.0                    0.0         0.0   \n",
      "3              0.0              6.0                    0.0         0.0   \n",
      "4              1.0              7.0                    0.0         1.0   \n",
      "\n",
      "   CSPL_RECEIVED_CALLS  year  month  day  hour  minute  \n",
      "0                  0.0  2011      4   24     1      30  \n",
      "1                  0.0  2011      4   24     1      30  \n",
      "2                  0.0  2011      4   24     1      30  \n",
      "3                  0.0  2011      4   24     1      30  \n",
      "4                  1.0  2011      4   24     1      30  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class FeatureExtractorClf(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y_df):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X_df):\n",
    "\n",
    "        XX = np.array([np.array(dd) for dd in X_df['ASS_ASSIGNMENT']])\n",
    "        return XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.n_components = 8\n",
    "        self.n_estimators = 400\n",
    "        self.clf = Pipeline([\n",
    "            #('pca', PCA(n_components=self.n_components)), \n",
    "            #('pca',  KernelPCA(n_components=21,kernel=\"rbf\",remove_zero_eig=True,gamma=0.0004)),\n",
    "            \n",
    "            ####### Basic algo :  Random Forest Classifier\n",
    "            #('clf', RandomForestClassifier(n_estimators=self.n_estimators, random_state=42))\n",
    "            \n",
    "            ####### GradientBoost\n",
    "            #('clf', GradientBoostingClassifier(n_estimators=self.n_estimators,max_depth=1000,subsample=0.85,\n",
    "            #       max_features='log2',random_state=42))\n",
    "                    \n",
    "                 \n",
    "           ####### AdaBoost avec DecisionTreeClassifier\n",
    "            ('clf', AdaBoostClassifier(\n",
    "                   base_estimator=DecisionTreeClassifier(max_depth=8),\n",
    "                   n_estimators=100,\n",
    "                   learning_rate=1.6,\n",
    "                   random_state=42,\n",
    "                   algorithm='SAMME',\n",
    "               ))\n",
    "                \n",
    "            #('clf', QuadraticDiscriminantAnalysis()),\n",
    "            #('clf', LinearDiscriminantAnalysis(solver='svd', shrinkage=None, priors=None, n_components=10, store_covariance=True, tol=0.01))\n",
    "            \n",
    "                \n",
    "                \n",
    "            ####### AdaBoost avec GradientBoostingClassifier\n",
    "            #('clf', AdaBoostClassifier(\n",
    "            #    base_estimator=GradientBoostingClassifier(n_estimators=10000,max_depth=10,\n",
    "            #       subsample=0.5,\n",
    "            #       max_features='log2'),\n",
    "            #    n_estimators=500,\n",
    "            #    learning_rate=1,\n",
    "            #    random_state=42,\n",
    "            #    algorithm='SAMME',\n",
    "            #))    \n",
    "            \n",
    "                \n",
    "            ####### AdaBoost avec SVC\n",
    "            #('clf', AdaBoostClassifier(\n",
    "            #    svc(probability=True, kernel='linear'),\n",
    "            #    n_estimators=10,\n",
    "            #    learning_rate=1,\n",
    "            #    random_state=42,\n",
    "            #    algorithm='SAMME',\n",
    "            #))\n",
    "                \n",
    "                \n",
    "            ####### AdaBoost avec GaussianNB\n",
    "            #('clf', AdaBoostClassifier(\n",
    "            #    GaussianNB(),\n",
    "            #  n_estimators=10,\n",
    "            #  learning_rate=1,\n",
    "            #  random_state=42,\n",
    "            #  algorithm='SAMME',\n",
    "            #))\n",
    "\n",
    "        \n",
    "            ####### AdaBoost avec SGDClassifier ou SVC\n",
    "            #('clf', AdaBoostClassifier(\n",
    "            #SGDClassifier(loss='log'),\n",
    "            #n_estimators=10000,\n",
    "            #learning_rate=1.6,\n",
    "            #random_state=42,\n",
    "            #algorithm='SAMME',\n",
    "             #))\n",
    "                \n",
    "\n",
    "            ####### Bayesien \n",
    "            #('clf',  GaussianNB())\n",
    "            \n",
    "            ####### Multinomial NB\n",
    "            #('clf', MultinomialNB(alpha=0.1, fit_prior=True, class_prior=None))\n",
    "                \n",
    "            ####### SGD \n",
    "            # ('clf',  SGDClassifier(loss='log')\n",
    "\n",
    "\n",
    "                ])        \n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = data['CSPL_RECEIVED_CALLS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print len( data['ASS_PARTNER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_df=data['CSPL_RECEIVED_CALLS'][:300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n"
     ]
    }
   ],
   "source": [
    "y_try=data['CSPL_RECEIVED_CALLS'][:3000000]\n",
    "print len(y_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "print len(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df=data[  ['WEEK_END',  'DAY_WE_DS',  'TPER_TEAM',  'ASS_ASSIGNMENT',  'ASS_DIRECTORSHIP','ASS_PARTNER','year','month','day','hour','minute']][:300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "print len(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nfrom sklearn.model_selection import ShuffleSplit\\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\\n\\ndef train_test_model_clf(X_df, y_df, skf_is, FeatureExtractor, Classifier):\\n    \\n    train_is, test_is = skf_is\\n    \\n   \\n    \\n    # Feature extraction\\n    fe_clf = FeatureExtractor()\\n    fe_clf.fit(X_train_df, y_train_df)\\n    \\n    X_train_array_clf = fe_clf.transform(X_train_df)\\n    X_test_array_clf = fe_clf.transform(X_test_df)\\n    \\n\\n    # Train\\n    clf = Classifier()\\n    clf.fit(X_train_array_clf, y_train_clf)\\n    # Test \\n    y_proba_clf = clf.predict_proba(X_test_array_clf)                        \\n    y_pred_clf = labels[np.argmax(y_proba_clf, axis=1)]#on somme les 4 valeurs pour obtenir le label  \\n    #print y_proba_clf\\n    #print y_pred_clf\\n    #print np.argmax(y_proba_clf, axis=1)\\n    error = 1 - accuracy_score(y_test_clf, y_pred_clf)                       \\n    print('error = %s' % error)                                                                            \\n    print('classification report:\\n %s' % classification_report(y_test_clf, y_pred_clf))\\n    print('confusion matrix:\\n %s' % confusion_matrix(y_test_clf, y_pred_clf))\\n\\n\\nskf = ShuffleSplit(n_splits=2, test_size=0.2, random_state=57)  \\nskf_is = list(skf.split(X_df))[0]\\n\\ntrain_test_model_clf(X_df, y_df, skf_is, FeatureExtractorClf, Classifier)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def train_test_model_clf(X_df, y_df, skf_is, FeatureExtractor, Classifier):\n",
    "    \n",
    "    train_is, test_is = skf_is\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Feature extraction\n",
    "    fe_clf = FeatureExtractor()\n",
    "    fe_clf.fit(X_train_df, y_train_df)\n",
    "    \n",
    "    X_train_array_clf = fe_clf.transform(X_train_df)\n",
    "    X_test_array_clf = fe_clf.transform(X_test_df)\n",
    "    \n",
    "\n",
    "    # Train\n",
    "    clf = Classifier()\n",
    "    clf.fit(X_train_array_clf, y_train_clf)\n",
    "    # Test \n",
    "    y_proba_clf = clf.predict_proba(X_test_array_clf)                        \n",
    "    y_pred_clf = labels[np.argmax(y_proba_clf, axis=1)]#on somme les 4 valeurs pour obtenir le label  \n",
    "    #print y_proba_clf\n",
    "    #print y_pred_clf\n",
    "    #print np.argmax(y_proba_clf, axis=1)\n",
    "    error = 1 - accuracy_score(y_test_clf, y_pred_clf)                       \n",
    "    print('error = %s' % error)                                                                            \n",
    "    print('classification report:\\n %s' % classification_report(y_test_clf, y_pred_clf))\n",
    "    print('confusion matrix:\\n %s' % confusion_matrix(y_test_clf, y_pred_clf))\n",
    "\n",
    "\n",
    "skf = ShuffleSplit(n_splits=2, test_size=0.2, random_state=57)  \n",
    "skf_is = list(skf.split(X_df))[0]\n",
    "\n",
    "train_test_model_clf(X_df, y_df, skf_is, FeatureExtractorClf, Classifier)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "End.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "clf3 = SGDClassifier()\n",
    "clf2 = AdaBoostClassifier(\n",
    "                   base_estimator=DecisionTreeClassifier(max_depth=8),\n",
    "                   n_estimators=1000,\n",
    "                   learning_rate=1.6,\n",
    "                   random_state=42,\n",
    "                   algorithm='SAMME',\n",
    "               )\n",
    "clf=Classifier()\n",
    "if len(X_df) > 0:\n",
    "    print \"Training...\"\n",
    "    X = np.array(X_df)\n",
    "    y = np.array(y_df).ravel()\n",
    "    clf.fit(X,y)\n",
    "print \"End.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data submission...\n",
      "End.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"Loading the data submission...\")\n",
    "file = open('/Users/ozad/Desktop/AXA/submission.txt','r')\n",
    "lines = [line.rstrip('\\n') for line in file]\n",
    "lines = lines[1:]\n",
    "submission = []\n",
    "for line in lines:\n",
    "    tokens = line.split()\n",
    "    date1 = tokens[0].split(\"-\")\n",
    "    date2 = tokens[1].split(\":\")\n",
    "    date = datetime(int(date1[0]),int(date1[1]),int(date1[2]),int(date2[0]),int(date2[1]))\n",
    "    ass_assignment = ' '.join(tokens[2:-1])\n",
    "    submission.append((date, ass_assignment))\n",
    "print \"End.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for validation...\n",
      "End.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = len(submission)\n",
    "print \"Loading data for validation...\"\n",
    "posTest=6820\n",
    "d_test = submission[len(submission)-1][0]\n",
    "X_test = []\n",
    "pos3=0\n",
    "while pos3 < m and submission[pos3][0] < d_test:\n",
    "    X_test.append([ data['ASS_ASSIGNMENT'][pos3] ])\n",
    "    pos3 += 1\n",
    "print \"End.\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82889\n"
     ]
    }
   ],
   "source": [
    "print len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 6 and input n_features is 1 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-fe11635789e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mpos3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"End.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ozad/anaconda/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \"\"\"\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ozad/anaconda/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    670\u001b[0m             pred = sum((estimator.predict(X) == classes).T * w\n\u001b[1;32m    671\u001b[0m                        for estimator, w in zip(self.estimators_,\n\u001b[0;32m--> 672\u001b[0;31m                                                self.estimator_weights_))\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_weights_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ozad/anaconda/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((estimator, w))\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             pred = sum((estimator.predict(X) == classes).T * w\n\u001b[0;32m--> 671\u001b[0;31m                        for estimator, w in zip(self.estimators_,\n\u001b[0m\u001b[1;32m    672\u001b[0m                                                self.estimator_weights_))\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ozad/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ozad/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    374\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 6 and input n_features is 1 "
     ]
    }
   ],
   "source": [
    "print \"Prediction...\"\n",
    "if len(X_test) > 0:\n",
    "    X_test = np.array(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "print pos3\n",
    "print \"End.\"\n",
    "\n",
    "####### affichage \n",
    "'''\n",
    "for i in range(pos3):\n",
    "    print \"%d-%d-%d %d:%d:00.000\\t%s\\t%d\" % (submission[i][0].year,\n",
    "        submission[i][0].month, submission[i][0].day,\n",
    "        submission[i][0].hour, submission[i][0].minute, submission[i][1],\n",
    "        y_pred[i])\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_submission(test, prediction, filename='/Users/ozad/Desktop/axa_data_challenge-master/submission.txt'):\n",
    "    \"\"\"\n",
    "    Create a submission file, \n",
    "    test: test dataset\n",
    "    prediction: predicted values\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('DATE\\tASS_ASSIGNMENT\\tprediction\\n')\n",
    "        submission_strings = test['DATE'] + '\\t' + test['ASS_ASSIGNMENT'] + '\\t'+ prediction.astype(str)\n",
    "        for row in submission_strings:\n",
    "            f.write(row + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_submission(X_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
