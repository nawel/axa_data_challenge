{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] graphlab.product_key: Unable to write current GraphLab Create license to /home/nawel/.graphlab/config. Ensure that this user account                         has write permission to /home/nawel/.graphlab/config to save the license for offline use.\n",
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1483481917.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to nawel.medjkoune@u-psud.fr and will expire on December 27, 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] graphlab.deploy._session: Unable to create session in specified location: '/home/nawel/.graphlab/artifacts'. Using: '/var/tmp/graphlab-nawel/54448/tmp_session_bef64323-6946-4df4-aeb1-fb98b8119f15'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import graphlab as gl\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pickle.load(open(\"gpCalles.obj\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataTest=pickle.load(open(\"testCalls.obj\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class FeatureExtractorClf(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y_df):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X_df):\n",
    "\n",
    "        XX = np.array([np.array(dd) for dd in X_df['ASS_ASSIGNMENT']])\n",
    "        return XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# Author:  Daro HENG <daro.heng@u-psud.fr>, \n",
    "# Licence: BSD 3 clause\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor                           \n",
    "from sklearn.decomposition import PCA                                            \n",
    "from sklearn.pipeline import Pipeline                                            \n",
    "from sklearn.base import BaseEstimator    \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np                                                               \n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "class Regressor(BaseEstimator):                                                  \n",
    "    def __init__(self):                                                          \n",
    "        self.n_components = 8                                                 \n",
    "        self.n_estimators = 150                                              \n",
    "        self.learning_rate = 0.2                                                \n",
    "        self.reg = Pipeline([                                      \n",
    "               #('pca', PCA(n_components=self.n_components)),        \n",
    "                            \n",
    "                ###### kernel PCA\n",
    "                #('pca',  KernelPCA(n_components=21,kernel=\"rbf\",remove_zero_eig=False)),\n",
    "\n",
    "\n",
    "                ###### Gradient Boosting Regressor\n",
    "                ('reg', GradientBoostingRegressor(max_depth=5, min_samples_leaf=10,n_estimators=self.n_estimators,learning_rate=self.learning_rate,random_state=42))\n",
    "\n",
    "                \n",
    "                ###### SVR\n",
    "                #('reg',SVR(C=1.0, cache_size=200, coef0=0.0, degree=6, epsilon=0.2, gamma='auto',kernel='rbf', max_iter=5, shrinking=True, tol=0.001, verbose=False))\n",
    "                \n",
    "                ##### linear model\n",
    "                #('reg',linear_model.LinearRegression(copy_X=True, fit_intercept=True, n_jobs=5, normalize=False))\n",
    "               \n",
    "                ##### MLP Regressor\n",
    "                #('reg',MLPRegressor(hidden_layer_sizes=(7,), activation='relu', solver='adam', alpha=0.0001, batch_size='auto',\n",
    "                #learning_rate='constant', learning_rate_init=1, power_t=0.5, max_iter=1000, shuffle=True, random_state=42, \n",
    "                #tol=0.0001, verbose=False, warm_start=False, momentum=0.09, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1,\n",
    "                #beta_1=0.9, beta_2=0.999, epsilon=1e-08))\n",
    "                \n",
    "               \n",
    "                ##### Neighbors Regressor\n",
    "                #('reg',RadiusNeighborsRegressor(radius=5.0))\n",
    "                \n",
    "                ##### PLS Regression\n",
    "                #('reg', PLSRegression(copy=True, max_iter=500, n_components=2, scale=True,tol=1e-06))\n",
    "                    \n",
    "                ##### Decision Tree Regressor\n",
    "                #('reg',DecisionTreeRegressor(max_depth=5))\n",
    "                    \n",
    "                ##### Random Forest Regressor\n",
    "                #('reg',RandomForestRegressor(n_estimators=100))\n",
    "                \n",
    "                ##### Ada Boost Regressor avec Decision Tree Regressor\n",
    "                #('reg', AdaBoostRegressor(DecisionTreeRegressor(max_depth=2),\n",
    "                #        n_estimators=3000, random_state=42))\n",
    "            ])                                                                   \n",
    "                                                                                 \n",
    "    def fit(self, X, y):\n",
    "        self.reg.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.reg.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit ...\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "# Author:  Daro HENG <daro.heng@u-psud.fr>, \n",
    "# Licence: BSD 3 clause\n",
    "\n",
    "import pickle\n",
    "import graphlab as gl\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np                                                               \n",
    "from utils import make_submission\n",
    "from regressor import Regressor\n",
    "\n",
    "\n",
    "labels = data['CSPL_RECEIVED_CALLS'].unique()\n",
    "\n",
    "#soustraire la moyenne\n",
    "mean_calls=data.groupby(['ASS_ASSIGNMENT', 'DAY_WE_DS','hour', 'minute']).mean().reset_index()\n",
    "std_calls=data.groupby(['ASS_ASSIGNMENT', 'DAY_WE_DS','hour', 'minute']).std().reset_index()\n",
    "data['MEAN_calls'] = pd.merge(data, mean_calls, how='left', on=['ASS_ASSIGNMENT', 'DAY_WE_DS','hour', 'minute'])['CSPL_RECEIVED_CALLS_y']\n",
    "data['CSPL_RECEIVED_CALLS']=data['CSPL_RECEIVED_CALLS']-data['MEAN_calls']\n",
    "\n",
    "#data['STD_calls'] = pd.merge(data, std_calls, how='left', on=['ASS_ASSIGNMENT', 'DAY_WE_DS','hour', 'minute'])['CSPL_RECEIVED_CALLS_y']\n",
    "#data['CSPL_RECEIVED_CALLS']=data['CSPL_RECEIVED_CALLS']/data['STD_calls']\n",
    "\n",
    "dataTest['MEAN_calls'] = pd.merge(dataTest, mean_calls, how='left', on=['ASS_ASSIGNMENT', 'DAY_WE_DS','hour', 'minute'])['CSPL_RECEIVED_CALLS']\n",
    "#dataTest['STD_calls'] = pd.merge(dataTest, std_calls, how='left', on=['ASS_ASSIGNMENT', 'DAY_WE_DS','hour', 'minute'])['CSPL_RECEIVED_CALLS']\n",
    "\n",
    "#### Load the X train and Y train\n",
    "Y_train=data['CSPL_RECEIVED_CALLS']\n",
    "X_train=data[  [  'DAY_WE_DS','cod_ASS_ASSIGNMENT','year','month','day','hour','minute']]\n",
    "X_test=dataTest[[  'DAY_WE_DS','cod_ASS_ASSIGNMENT','year','month','day','hour','minute']]\n",
    "\n",
    "Y_train=np.array(Y_train)\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "\n",
    "#### fit \n",
    "print \"Fit ...\"\n",
    "reg=Regressor()\n",
    "reg.fit(X_train, Y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction ...\n",
      "Write the submission ...\n",
      "End.\n"
     ]
    }
   ],
   "source": [
    "#### Prediction\n",
    "print \"Prediction ...\"\n",
    "Y_pred = reg.predict(X_test)\n",
    "#rajouter le mean\n",
    "Y_pred=(Y_pred)+dataTest['MEAN_calls']\n",
    "Y_pred=Y_pred.apply(lambda x: (x,-x)[x<0])\n",
    "#### write the submission\n",
    "print \"Write the submission ...\"\n",
    "make_submission1(dataTest,Y_pred)\n",
    "\n",
    "print \"End.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969.11455172413775"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-193.74520306513421"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred=Y_pred+dataTest['MEAN_calls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.000000e+00\n",
       "1        0.000000e+00\n",
       "2        0.000000e+00\n",
       "3        0.000000e+00\n",
       "4        7.103754e-03\n",
       "5        2.550222e-02\n",
       "6        0.000000e+00\n",
       "7        3.882542e-02\n",
       "8        2.473175e-01\n",
       "9        1.882059e-01\n",
       "10       1.871120e+01\n",
       "11       0.000000e+00\n",
       "12       2.971305e-01\n",
       "13       1.872966e-02\n",
       "14       7.177043e-01\n",
       "15       2.415151e-02\n",
       "16       1.930538e-01\n",
       "17       6.107863e+00\n",
       "18       0.000000e+00\n",
       "19       0.000000e+00\n",
       "20       9.372167e-03\n",
       "21       0.000000e+00\n",
       "22       0.000000e+00\n",
       "23       0.000000e+00\n",
       "24       0.000000e+00\n",
       "25       1.180556e-02\n",
       "26       3.871354e-01\n",
       "27       3.127182e-02\n",
       "28       1.326180e+01\n",
       "29       2.846863e-02\n",
       "             ...     \n",
       "82879    1.398707e+00\n",
       "82880    4.867203e-01\n",
       "82881    0.000000e+00\n",
       "82882    2.287429e+00\n",
       "82883    5.692779e-02\n",
       "82884    1.601338e+00\n",
       "82885    1.549768e+01\n",
       "82886    1.671986e+00\n",
       "82887    7.126841e-01\n",
       "82888    5.859311e+01\n",
       "82889    6.302806e-02\n",
       "82890    0.000000e+00\n",
       "82891    0.000000e+00\n",
       "82892    0.000000e+00\n",
       "82893    0.000000e+00\n",
       "82894    0.000000e+00\n",
       "82895    0.000000e+00\n",
       "82896    0.000000e+00\n",
       "82897    1.665335e-16\n",
       "82898    0.000000e+00\n",
       "82899    2.086039e+00\n",
       "82900    1.540680e-01\n",
       "82901    0.000000e+00\n",
       "82902    1.640471e+00\n",
       "82903    6.789878e-01\n",
       "82904    8.403615e-01\n",
       "82905    1.148797e+01\n",
       "82906    1.882914e+00\n",
       "82907    2.090246e+00\n",
       "82908    4.819649e+01\n",
       "Name: MEAN_calls, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "def make_submission1(test, prediction, filename='submission.txt'):\n",
    "    \"\"\"\n",
    "    Create a submission file, \n",
    "    test: test dataset\n",
    "    prediction: predicted values\n",
    "    \"\"\"\n",
    "    filename='submission-%s.txt'%datetime.now().strftime('%Y-%m-%d-%H:%M')\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('DATE\\tASS_ASSIGNMENT\\tprediction\\n')\n",
    "        submission_strings = test['DATE'] + '\\t' + test['ASS_ASSIGNMENT'] + '\\t'+ prediction.astype(str)\n",
    "        for row in submission_strings:\n",
    "            f.write(row + '\\n') \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300.48275862068897"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(dataTest['MEAN_calls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
