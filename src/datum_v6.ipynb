{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] graphlab.product_key: Unable to write current GraphLab Create license to /home/nawel/.graphlab/config. Ensure that this user account                         has write permission to /home/nawel/.graphlab/config to save the license for offline use.\n",
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1483559820.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to nawel.medjkoune@u-psud.fr and will expire on December 27, 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] graphlab.deploy._session: Unable to create session in specified location: '/home/nawel/.graphlab/artifacts'. Using: '/var/tmp/graphlab-nawel/4418/tmp_session_d3a4a8f8-269f-45bf-8411-39ad0713bf0b'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import graphlab as gl\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pickle.load(open(\"gpCalles.obj\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataTest=pickle.load(open(\"testCalls.obj\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# Author:  Daro HENG <daro.heng@u-psud.fr>, \n",
    "# Licence: BSD 3 clause\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor                           \n",
    "from sklearn.decomposition import PCA                                            \n",
    "from sklearn.pipeline import Pipeline                                            \n",
    "from sklearn.base import BaseEstimator    \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np                                                               \n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "class Regressor(BaseEstimator):                                                  \n",
    "    def __init__(self):    \n",
    "        self.n_components = 8                                                 \n",
    "        self.n_estimators = 150                                              \n",
    "        self.learning_rate = 0.2                                                \n",
    "        self.reg = Pipeline([                                      \n",
    "               #('pca', PCA(n_components=self.n_components)),        \n",
    "                            \n",
    "                ###### kernel PCA\n",
    "                #('pca',  KernelPCA(n_components=21,kernel=\"rbf\",remove_zero_eig=False)),\n",
    "\n",
    "\n",
    "                ###### Gradient Boosting Regressor\n",
    "                #('reg', GradientBoostingRegressor(max_depth=5, min_samples_leaf=10,n_estimators=self.n_estimators,learning_rate=self.learning_rate,random_state=42))\n",
    "\n",
    "                \n",
    "                ###### SVR\n",
    "                ('reg',SVR(C=1.0, cache_size=200, coef0=0.0, degree=6, epsilon=0.2, gamma='auto',kernel='rbf', max_iter=100, shrinking=True, tol=0.001, verbose=False))\n",
    "                \n",
    "                ##### linear model\n",
    "                #('reg',linear_model.LinearRegression(copy_X=True, fit_intercept=True, n_jobs=5, normalize=False))\n",
    "               \n",
    "                ##### MLP Regressor\n",
    "                #('reg',MLPRegressor(hidden_layer_sizes=(7,), activation='relu', solver='adam', alpha=0.0001, batch_size='auto',\n",
    "                #learning_rate='constant', learning_rate_init=1, power_t=0.5, max_iter=1000, shuffle=True, random_state=42, \n",
    "                #tol=0.0001, verbose=False, warm_start=False, momentum=0.09, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1,\n",
    "                #beta_1=0.9, beta_2=0.999, epsilon=1e-08))\n",
    "                \n",
    "               \n",
    "                ##### Neighbors Regressor\n",
    "                #('reg',RadiusNeighborsRegressor(radius=5.0))\n",
    "                \n",
    "                ##### PLS Regression\n",
    "                #('reg', PLSRegression(copy=True, max_iter=500, n_components=2, scale=True,tol=1e-06))\n",
    "                    \n",
    "                ##### Decision Tree Regressor\n",
    "                #('reg',DecisionTreeRegressor(max_depth=5))\n",
    "                    \n",
    "                ##### Random Forest Regressor\n",
    "                #('reg',RandomForestRegressor(n_estimators=100))\n",
    "                \n",
    "                ##### Ada Boost Regressor avec Decision Tree Regressor\n",
    "                #('reg', AdaBoostRegressor(DecisionTreeRegressor(max_depth=2),\n",
    "                #        n_estimators=3000, random_state=42))\n",
    "            ])                                                                   \n",
    "                                                                                 \n",
    "    def fit(self, X, y):\n",
    "        self.reg.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.reg.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Loading the data train ...\n",
      "Loading the X and Y train ...\n",
      "Loading the X  test ...\n",
      " Train et Predict the categorie :  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawel/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train et Predict the categorie :  1\n",
      " Train et Predict the categorie :  2\n",
      " Train et Predict the categorie :  3\n",
      " Train et Predict the categorie :  4\n",
      " Train et Predict the categorie :  5\n",
      " Train et Predict the categorie :  6\n",
      " Train et Predict the categorie :  7\n",
      " Train et Predict the categorie :  8\n",
      " Train et Predict the categorie :  9\n",
      " Train et Predict the categorie :  10\n",
      " Train et Predict the categorie :  11\n",
      " Train et Predict the categorie :  12\n",
      " Train et Predict the categorie :  13\n",
      " Train et Predict the categorie :  14\n",
      " Train et Predict the categorie :  15\n",
      " Train et Predict the categorie :  16\n",
      " Train et Predict the categorie :  17\n",
      " Train et Predict the categorie :  18\n",
      " Train et Predict the categorie :  19\n",
      " Train et Predict the categorie :  20\n",
      " Train et Predict the categorie :  21\n",
      " Train et Predict the categorie :  22\n",
      " Train et Predict the categorie :  23\n",
      " Train et Predict the categorie :  24\n",
      " Train et Predict the categorie :  25\n",
      " Train et Predict the categorie :  26\n",
      " Train et Predict the categorie :  27\n",
      "Write the submission ...\n",
      "End.\n"
     ]
    }
   ],
   "source": [
    "print \"Start\"\n",
    "print \"Loading the data train ...\"\n",
    "\n",
    "#print \"Creat Mean_calls\"\n",
    "#soustraire la moyenne\n",
    "#mean_calls=data.groupby(['ASS_ASSIGNMENT', 'DAY_WE_DS','hour', 'minute']).mean().reset_index()\n",
    "#data['MEAN_calls'] = pd.merge(data, mean_calls, how='left', on=['ASS_ASSIGNMENT', 'DAY_WE_DS','hour', 'minute'])['CSPL_RECEIVED_CALLS_y']\n",
    "#data['CSPL_RECEIVED_CALLS']=data['CSPL_RECEIVED_CALLS']-data['MEAN_calls']\n",
    "#dataTest['MEAN_calls'] = pd.merge(dataTest, mean_calls, how='left', on=['ASS_ASSIGNMENT', 'DAY_WE_DS','hour', 'minute'])['MEAN_calls']\n",
    "\n",
    "\n",
    "\n",
    "print \"Loading the X and Y train ...\"\n",
    "set_X_train=[]\n",
    "set_Y_train=[]\n",
    "i=0\n",
    "while i < len(data['cod_ASS_ASSIGNMENT'].unique()):\n",
    "\tset_X_train.append(data[['DATE','DAY_WE_DS', 'year','month','day','hour','minute', 'cod_ASS_ASSIGNMENT']][data['cod_ASS_ASSIGNMENT']==(i)])\n",
    "\tset_Y_train.append(data['CSPL_RECEIVED_CALLS'][data['cod_ASS_ASSIGNMENT' ]==(i)])\n",
    "\ti=i+1\n",
    "\n",
    "print \"Loading the X  test ...\"\n",
    "set_X_test=[]\n",
    "i=0\n",
    "while i < len(data['cod_ASS_ASSIGNMENT'].unique()):\n",
    "\tset_X_test.append(dataTest[[ 'DATE','DAY_WE_DS', 'year','month','day','hour','minute', 'cod_ASS_ASSIGNMENT']][dataTest['cod_ASS_ASSIGNMENT' ]==(i)])\n",
    "\ti=i+1\n",
    "\n",
    "i=0\n",
    "listPred=[]\n",
    "while i<len(set_X_train):\n",
    "        from sklearn import preprocessing as pre\n",
    "        scaler = pre.StandardScaler().fit(set_X_train[i][['DAY_WE_DS', 'year' ,'month','day','hour','minute']])\n",
    "        X_train_scaled = scaler.transform(set_X_train[i][['DAY_WE_DS', 'year','month','day','hour','minute']])\n",
    "        print \" Train et Predict the categorie : \",i\n",
    "        reg=Regressor()\n",
    "        reg.fit(X_train_scaled, set_Y_train[i])\n",
    "        if(len(set_X_test[i])>0):            \n",
    "            X_test_scaled = scaler.transform(set_X_test[i][['DAY_WE_DS', 'year','month','day','hour','minute']])\n",
    "            listPred.append( reg.predict(X_test_scaled))\n",
    "        i=i+1\n",
    "\n",
    "\n",
    "l=0\n",
    "i=0\n",
    "while l<len(set_X_test):\n",
    "\tif(len(set_X_test[l])>0):\n",
    "\t\tset_X_test[l]['CSPL_RECEIVED_CALLS'] =   listPred[i]\n",
    "\t\ti=i+1\n",
    "\tl=l+1\n",
    "\n",
    "\n",
    "\n",
    "#on réassemble les valeurs de prédiction\n",
    "resultPred= pd.concat(set_X_test)\n",
    "resultPred=resultPred.sort_index()\n",
    "\n",
    "def make_submission(test, prediction, filename='submission_.txt'):\n",
    "\t\"\"\"\n",
    "\tCreate a submission file, \n",
    "\ttest: test dataset\n",
    "\tprediction: predicted values\n",
    "\t\"\"\"\n",
    "\twith open(filename, 'w') as f:\n",
    "\t\tf.write('DATE\\tASS_ASSIGNMENT\\tprediction\\n')\n",
    "\t\tsubmission_strings = test['DATE'] + '\\t' + test['ASS_ASSIGNMENT'] + '\\t'+ prediction['CSPL_RECEIVED_CALLS'].astype(str)\n",
    "\t\tfor row in submission_strings:\n",
    "\t\t\tf.write(row + '\\n') \n",
    "\n",
    "\n",
    "#### write the submission\n",
    "print \"Write the submission ...\"\n",
    "make_submission(dataTest,resultPred)\n",
    "\n",
    "print \"End.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# time series (brouillon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = data[['CSPL_RECEIVED_CALLS','DAY_WE_DS','cod_ASS_ASSIGNMENT','year','month','day','hour','minute', 'DATE']]\n",
    "df=df[df.cod_ASS_ASSIGNMENT==1]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.plot(x=\"DATE\", y=\"CSPL_RECEIVED_CALLS\", figsize=(14,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.tsatools import detrend\n",
    "notrend = detrend(df.CSPL_RECEIVED_CALLS)\n",
    "df[\"notrend\"] = notrend\n",
    "df.plot(x=\"DATE\", y=[\"CSPL_RECEIVED_CALLS\", \"notrend\"], figsize=(14,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "cor = acf(df.notrend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(cor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import pacf\n",
    "pcor = pacf(df.notrend)\n",
    "plt.plot(pcor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"diff\"] = numpy.nan\n",
    "df.ix[1, \"diff\"]=0\n",
    "df.ix[2:, \"diff\"] = (df.iloc[1:, 0].as_matrix() - df.iloc[:len(df)-1, 0].as_matrix())\n",
    "#pd.concat([df.head(n=5), df.tail(n=6)])\n",
    "df.plot(x=\"DATE\", y=\"diff\", figsize=(14,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARMA\n",
    "arma_mod = ARMA(df[\"diff\"].dropna().as_matrix(), order=(8, 1))\n",
    "res = arma_mod.fit()\n",
    "res.params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.tsatools import lagmat\n",
    "lag = 2\n",
    "X = lagmat(df[\"diff\"], lag)\n",
    "lagged = df.copy()\n",
    "for c in range(1,lag+1):\n",
    "    lagged[\"lag%d\" % c] = X[:, c-1]\n",
    "#pd.concat([lagged.head(), lagged.tail()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xc = [\"lag%d\" % i for i in range(1,lag+1)]\n",
    "split = 0.66\n",
    "isplit = int(len(lagged) * split)\n",
    "xt = lagged[10:][xc]\n",
    "yt = lagged[10:][\"diff\"]\n",
    "X_train, y_train, X_test, y_test = xt[:isplit], yt[:isplit], xt[isplit:], yt[isplit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clr = LinearRegression()\n",
    "clr.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test.as_matrix(), clr.predict(X_test))\n",
    "r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "clrf = RandomForestRegressor()\n",
    "clrf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test.as_matrix(), clrf.predict(X_test))\n",
    "r2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
