{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] graphlab.product_key: Unable to write current GraphLab Create license to /home/nawel/.graphlab/config. Ensure that this user account                         has write permission to /home/nawel/.graphlab/config to save the license for offline use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to nawel.medjkoune@u-psud.fr and will expire on December 27, 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1483616300.log\n",
      "[WARNING] graphlab.deploy._session: Unable to create session in specified location: '/home/nawel/.graphlab/artifacts'. Using: '/var/tmp/graphlab-nawel/12588/tmp_session_a0b7db58-71c7-4a67-a7ca-8bef716ff58d'\n",
      "/home/nawel/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import graphlab as gl\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pickle.load(open(\"gpCalles.obj\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataTest=pickle.load(open(\"testCalls.obj\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# Author:  Daro HENG <daro.heng@u-psud.fr>, \n",
    "# Licence: BSD 3 clause\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor                           \n",
    "from sklearn.decomposition import PCA                                            \n",
    "from sklearn.pipeline import Pipeline                                            \n",
    "from sklearn.base import BaseEstimator    \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np                                                               \n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "class Regressor(BaseEstimator):                                                  \n",
    "    def __init__(self):    \n",
    "        self.n_components = 8                                                 \n",
    "        self.n_estimators = 200                                             \n",
    "        self.learning_rate = 0.5                                                \n",
    "        self.reg = Pipeline([                                      \n",
    "               #('pca', PCA(n_components=self.n_components)),        \n",
    "                            \n",
    "                ###### kernel PCA\n",
    "                #('pca',  KernelPCA(n_components=21,kernel=\"rbf\",remove_zero_eig=False)),\n",
    "\n",
    "\n",
    "                ###### Gradient Boosting Regressor\n",
    "                ('reg', GradientBoostingRegressor(max_depth=10, min_samples_leaf=10,n_estimators=self.n_estimators,learning_rate=self.learning_rate,random_state=42))\n",
    "\n",
    "                \n",
    "                ###### SVR\n",
    "                #('reg',SVR(C=1.0, cache_size=200, coef0=0.0, degree=6, epsilon=0.2, gamma='auto',kernel='rbf', max_iter=100, shrinking=True, tol=0.001, verbose=False))\n",
    "                \n",
    "                ##### linear model\n",
    "                #('reg',linear_model.LinearRegression(copy_X=True, fit_intercept=True, n_jobs=5, normalize=False))\n",
    "               \n",
    "                ##### MLP Regressor\n",
    "                #('reg',MLPRegressor(hidden_layer_sizes=(7,), activation='relu', solver='adam', alpha=0.0001, batch_size='auto',\n",
    "                #learning_rate='constant', learning_rate_init=1, power_t=0.5, max_iter=1000, shuffle=True, random_state=42, \n",
    "                #tol=0.0001, verbose=False, warm_start=False, momentum=0.09, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1,\n",
    "                #beta_1=0.9, beta_2=0.999, epsilon=1e-08))\n",
    "                \n",
    "               \n",
    "                ##### Neighbors Regressor\n",
    "                #('reg',RadiusNeighborsRegressor(radius=5.0))\n",
    "                \n",
    "                ##### PLS Regression\n",
    "                #('reg', PLSRegression(copy=True, max_iter=500, n_components=2, scale=True,tol=1e-06))\n",
    "                    \n",
    "                ##### Decision Tree Regressor\n",
    "                #('reg',DecisionTreeRegressor(max_depth=5))\n",
    "                    \n",
    "                ##### Random Forest Regressor\n",
    "                #('reg',RandomForestRegressor(n_estimators=100))\n",
    "                \n",
    "                ##### Ada Boost Regressor avec Decision Tree Regressor\n",
    "                #('reg', AdaBoostRegressor(DecisionTreeRegressor(max_depth=2),\n",
    "                #        n_estimators=3000, random_state=42))\n",
    "            ])                                                                   \n",
    "                                                                                 \n",
    "    def fit(self, X, y):\n",
    "        self.reg.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.reg.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Loading the data train ...\n",
      "Loading the X and Y train ...\n",
      "Loading the X  test ...\n",
      " Train et Predict the categorie :  0\n",
      "Cross validation ... 0\n",
      "The score mean of cross validation :  -0.456131767998\n",
      " Train et Predict the categorie :  1\n",
      "Cross validation ... 1\n",
      "The score mean of cross validation :  -21.980871621\n",
      " Train et Predict the categorie :  2\n",
      "Cross validation ... 2\n",
      "The score mean of cross validation :  -0.00472808634775\n",
      " Train et Predict the categorie :  3\n",
      "Cross validation ... 3\n",
      "The score mean of cross validation :  -12.6734531725\n",
      " Train et Predict the categorie :  4\n",
      "Cross validation ... 4\n",
      "The score mean of cross validation :  -0.225255584868\n",
      " Train et Predict the categorie :  5\n",
      "Cross validation ... 5\n",
      "The score mean of cross validation :  -1.00006431634\n",
      " Train et Predict the categorie :  6\n",
      "Cross validation ... 6\n",
      "The score mean of cross validation :  -0.436753040048\n",
      " Train et Predict the categorie :  7\n",
      "Cross validation ... 7\n",
      "The score mean of cross validation :  -0.0080514946126\n",
      " Train et Predict the categorie :  8\n",
      "Cross validation ... 8\n",
      "The score mean of cross validation :  -1.5018100915\n",
      " Train et Predict the categorie :  9\n",
      "Cross validation ... 9\n",
      "The score mean of cross validation :  -0.0760561110752\n",
      " Train et Predict the categorie :  10\n",
      "Cross validation ... 10\n",
      "The score mean of cross validation :  -17.436110211\n",
      " Train et Predict the categorie :  11\n",
      "Cross validation ... 11\n",
      "The score mean of cross validation :  -12.6317628246\n",
      " Train et Predict the categorie :  12\n",
      "Cross validation ... 12\n",
      "The score mean of cross validation :  -20.2353487181\n",
      " Train et Predict the categorie :  13\n",
      "Cross validation ... 13\n",
      "The score mean of cross validation :  -1.13652441293\n",
      " Train et Predict the categorie :  14\n",
      "Cross validation ... 14\n",
      "The score mean of cross validation :  -1.76670389043\n",
      " Train et Predict the categorie :  15\n",
      "Cross validation ... 15\n",
      "The score mean of cross validation :  -29.8927530137\n",
      " Train et Predict the categorie :  16\n",
      "Cross validation ... 16\n",
      "The score mean of cross validation :  -602.520076006\n",
      " Train et Predict the categorie :  17\n",
      "Cross validation ... 17\n",
      "The score mean of cross validation :  -26.904237278\n",
      " Train et Predict the categorie :  18\n",
      "Cross validation ... 18\n",
      "The score mean of cross validation :  -2203.21469388\n",
      " Train et Predict the categorie :  19\n",
      "Cross validation ... 19\n",
      "The score mean of cross validation :  -60.9288706253\n",
      " Train et Predict the categorie :  20\n",
      "Cross validation ... 20\n",
      "The score mean of cross validation :  -1.27699912034\n",
      " Train et Predict the categorie :  21\n",
      "Cross validation ... 21\n",
      "The score mean of cross validation :  -0.373667067088\n",
      " Train et Predict the categorie :  22\n",
      "Cross validation ... 22\n",
      "The score mean of cross validation :  -236.421138592\n",
      " Train et Predict the categorie :  23\n",
      "Cross validation ... 23\n",
      "The score mean of cross validation :  -0.0611427743593\n",
      " Train et Predict the categorie :  24\n",
      "Cross validation ... 24\n",
      "The score mean of cross validation :  -0.0236791058461\n",
      " Train et Predict the categorie :  25\n",
      "Cross validation ... 25\n",
      "The score mean of cross validation :  -7.24092560765\n",
      " Train et Predict the categorie :  26\n",
      "Cross validation ... 26\n",
      "The score mean of cross validation :  -0.0259073478683\n",
      " Train et Predict the categorie :  27\n",
      "Cross validation ... 27\n",
      "The score mean of cross validation :  -9878.89807282\n",
      "Write the submission ...\n",
      "End.\n",
      "CV score global -469.262563878\n"
     ]
    }
   ],
   "source": [
    "print \"Start\"\n",
    "print \"Loading the data train ...\"\n",
    "\n",
    "#print \"Creat Mean_calls\"\n",
    "#soustraire la moyenne\n",
    "#mean_calls=data.groupby(['ASS_ASSIGNMENT', 'DAY_WE_DS','hour', 'minute']).mean().reset_index()\n",
    "#data['MEAN_calls'] = pd.merge(data, mean_calls, how='left', on=['ASS_ASSIGNMENT', 'DAY_WE_DS','hour', 'minute'])['CSPL_RECEIVED_CALLS_y']\n",
    "#data['CSPL_RECEIVED_CALLS']=data['CSPL_RECEIVED_CALLS']-data['MEAN_calls']\n",
    "#dataTest['MEAN_calls'] = pd.merge(dataTest, mean_calls, how='left', on=['ASS_ASSIGNMENT', 'DAY_WE_DS','hour', 'minute'])['MEAN_calls']\n",
    "\n",
    "\n",
    "\n",
    "print \"Loading the X and Y train ...\"\n",
    "set_X_train=[]\n",
    "set_Y_train=[]\n",
    "i=0\n",
    "while i < len(data['cod_ASS_ASSIGNMENT'].unique()):\n",
    "\tset_X_train.append(data[['DATE','DAY_WE_DS', 'year','month','day','hour','minute', 'cod_ASS_ASSIGNMENT']][data['cod_ASS_ASSIGNMENT']==(i)])\n",
    "\tset_Y_train.append(data['CSPL_RECEIVED_CALLS'][data['cod_ASS_ASSIGNMENT' ]==(i)])\n",
    "\ti=i+1\n",
    "\n",
    "print \"Loading the X  test ...\"\n",
    "set_X_test=[]\n",
    "i=0\n",
    "while i < len(data['cod_ASS_ASSIGNMENT'].unique()):\n",
    "\tset_X_test.append(dataTest[[ 'DATE','DAY_WE_DS', 'year','month','day','hour','minute', 'cod_ASS_ASSIGNMENT']][dataTest['cod_ASS_ASSIGNMENT' ]==(i)])\n",
    "\ti=i+1\n",
    "\n",
    "i=0\n",
    "listPred=[]\n",
    "score_cv_global=[]\n",
    "while i<len(set_X_train):\n",
    "        from sklearn import preprocessing as pre\n",
    "        scaler = pre.StandardScaler().fit(set_X_train[i][['DAY_WE_DS', 'year' ,'month','day','hour','minute']])\n",
    "        X_train_scaled = scaler.transform(set_X_train[i][['DAY_WE_DS', 'year','month','day','hour','minute']])\n",
    "        print \" Train et Predict the categorie : \",i\n",
    "        reg=Regressor()\n",
    "        reg.fit(X_train_scaled, set_Y_train[i])\n",
    "        #### Cross validation\n",
    "        print \"Cross validation ...\", i\n",
    "        #loo = cross_validation.LeaveOneOut(len(y_df))\n",
    "        loo=10\n",
    "        scores = cross_validation.cross_val_score(reg, X_train_scaled, set_Y_train[i], scoring='neg_mean_squared_error', cv=loo,)\n",
    "        print \"The score mean of cross validation : \", scores.mean()\n",
    "        score_cv_global.append(scores.mean())\n",
    "\n",
    "        if(len(set_X_test[i])>0):            \n",
    "            X_test_scaled = scaler.transform(set_X_test[i][['DAY_WE_DS', 'year','month','day','hour','minute']])\n",
    "            listPred.append( reg.predict(X_test_scaled))\n",
    "        i=i+1\n",
    "\n",
    "\n",
    "l=0\n",
    "i=0\n",
    "while l<len(set_X_test):\n",
    "\tif(len(set_X_test[l])>0):\n",
    "\t\tset_X_test[l]['CSPL_RECEIVED_CALLS'] =   listPred[i]\n",
    "\t\ti=i+1\n",
    "\tl=l+1\n",
    "\n",
    "\n",
    "\n",
    "#on réassemble les valeurs de prédiction\n",
    "resultPred= pd.concat(set_X_test)\n",
    "resultPred=resultPred.sort_index()\n",
    "\n",
    "def make_submission(test, prediction, filename='submission_.txt'):\n",
    "\t\"\"\"\n",
    "\tCreate a submission file, \n",
    "\ttest: test dataset\n",
    "\tprediction: predicted values\n",
    "\t\"\"\"\n",
    "\twith open(filename, 'w') as f:\n",
    "\t\tf.write('DATE\\tASS_ASSIGNMENT\\tprediction\\n')\n",
    "\t\tsubmission_strings = test['DATE'] + '\\t' + test['ASS_ASSIGNMENT'] + '\\t'+ prediction['CSPL_RECEIVED_CALLS'].astype(str)\n",
    "\t\tfor row in submission_strings:\n",
    "\t\t\tf.write(row + '\\n') \n",
    "\n",
    "\n",
    "#### write the submission\n",
    "print \"Write the submission ...\"\n",
    "make_submission(dataTest,resultPred)\n",
    "\n",
    "print \"End.\"\n",
    "print \"CV score global\" , np.mean(score_cv_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultPred['CSPL_RECEIVED_CALLS']=resultPred['CSPL_RECEIVED_CALLS'].apply(lambda x: x*(x>0))\n",
    "resultPred['CSPL_RECEIVED_CALLS']=resultPred['CSPL_RECEIVED_CALLS'].apply(lambda x: math.ceil(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_submission(dataTest,resultPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5456.0\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "x=5455.2568\n",
    "print math.ceil(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(linex, greater_is_better=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import  make_scorer\n",
    "\n",
    "def linex(y, y_pred):\n",
    "    import numpy as np\n",
    "    return np.exp(-0.1*(y-y_pred))+0.1*(y-y_pred)-1\n",
    "linex_scorer = make_scorer(linex, greater_is_better=False)\n",
    "linex_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# time series (brouillon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = data[['CSPL_RECEIVED_CALLS','DAY_WE_DS','cod_ASS_ASSIGNMENT','year','month','day','hour','minute', 'DATE']]\n",
    "df=df[df.cod_ASS_ASSIGNMENT==1]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.plot(x=\"DATE\", y=\"CSPL_RECEIVED_CALLS\", figsize=(14,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.tsatools import detrend\n",
    "notrend = detrend(df.CSPL_RECEIVED_CALLS)\n",
    "df[\"notrend\"] = notrend\n",
    "df.plot(x=\"DATE\", y=[\"CSPL_RECEIVED_CALLS\", \"notrend\"], figsize=(14,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "cor = acf(df.notrend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(cor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import pacf\n",
    "pcor = pacf(df.notrend)\n",
    "plt.plot(pcor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"diff\"] = numpy.nan\n",
    "df.ix[1, \"diff\"]=0\n",
    "df.ix[2:, \"diff\"] = (df.iloc[1:, 0].as_matrix() - df.iloc[:len(df)-1, 0].as_matrix())\n",
    "#pd.concat([df.head(n=5), df.tail(n=6)])\n",
    "df.plot(x=\"DATE\", y=\"diff\", figsize=(14,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARMA\n",
    "arma_mod = ARMA(df[\"diff\"].dropna().as_matrix(), order=(8, 1))\n",
    "res = arma_mod.fit()\n",
    "res.params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.tsatools import lagmat\n",
    "lag = 2\n",
    "X = lagmat(df[\"diff\"], lag)\n",
    "lagged = df.copy()\n",
    "for c in range(1,lag+1):\n",
    "    lagged[\"lag%d\" % c] = X[:, c-1]\n",
    "#pd.concat([lagged.head(), lagged.tail()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xc = [\"lag%d\" % i for i in range(1,lag+1)]\n",
    "split = 0.66\n",
    "isplit = int(len(lagged) * split)\n",
    "xt = lagged[10:][xc]\n",
    "yt = lagged[10:][\"diff\"]\n",
    "X_train, y_train, X_test, y_test = xt[:isplit], yt[:isplit], xt[isplit:], yt[isplit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clr = LinearRegression()\n",
    "clr.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test.as_matrix(), clr.predict(X_test))\n",
    "r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "clrf = RandomForestRegressor()\n",
    "clrf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test.as_matrix(), clrf.predict(X_test))\n",
    "r2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
